==== NOISE / MISC (-1) (n=5) ====

--- DOC: University of Oxford | What do people want? Views on platforms and the digital public sphere in eight countries | Reuters Institute for the Study of Journalism
In this piece What do people want? Views on platforms and the digital public sphere in eight countries In this piece Executive summary | Introduction | Methodology | Chapter 1: Public use of platforms for political news and information | Chapter 2: Platforms and their relationship to politics and democracy | Chapter 3: Platform policy, responsibility, and governance | Chapter 4: Public perception of platforms more generally | Conclusion | References | Footnotes | Download the data | About the authors | AcknowledgementsDOI: 10.60625/risj-8pk9-d398 Executive summary The purpose of this report is to analyse the role of digital platforms in contemporary media environments, including public perception of the benefits and problems they bring, especially when it comes to news and

--- DOC: Imperial College London | National State of Patient Safety 2024
National State of Patient Safety 2024: Prioritising improvement efforts in a system under stress Executive summary This report presents the national state of patient safety in England in 2024. Two years on from our first report, we provide an updated analysis of the publicly available data. Our report concludes that performance in key areas such as maternity care has deteriorated, requiring urgent attention. Our 2022 report stated that progress in the safety of maternity services needed to accelerate. Instead, it has worsened. Poor care exposed in recent investigations and inquiries is sadly confirmed by the data. For the first time in a decade, rates of maternal and neonatal deaths have risen and continue to rise. The data also show that

--- DOC: London School of Economics and Political Science | Contributors A-C | USAPP
Manuel B. Aalbers – KU Leuven Manuel B. Aalbers is associate professor of Human Geography at KU Leuven, Belgium, where he leads the research group The Real Estate/Financial Complex. Before that, he was at the Universality of Amsterdam and Columbia University, New York. He has an interest in housing policy, mortgage markets, social exclusion, gentrification and urban development. His latest book is The Financialization of Housing. He also edited the book Subprime Cities. Read articles by Manuel B. Aalbers. Aleksi Aaltonen – Warwick Business School Aleksi Aaltonenis an assistant professor of information systems at Warwick Business School. Aleksi also cofounded smartphone app Moves, and serves as the Chairman of the Demos Helsinki think tank. Read articles by Aleksi Aaltonen. _

--- DOC: University of Oxford | Features | University of Oxford
Features Antimicrobial resistance (AMR) is one the most pressing challenges facing the world today. Common infections that were once easily treated by antibiotics are becoming life-threatening again. By 2050 it is predicted that over 10 million deaths will be caused by drug-resistant infections every year. At the Ineos Oxford Institute for antimicrobial research (IOI), created in 2021 to advance antimicrobial research, Oxford’s graduate students are among those contributing to the search for solutions to tackle this growing threat to global health. 34 DPhil students from around the world are based at the IOI, each part of a focused research project that works to develop new antibiotics or study the spread and impact of AMR around the world. Working closely with

--- DOC: London School of Economics and Political Science | The British Constitution’s failure to manage existential risk: back to basics - LSE BREXIT
Brexit comes at a precarious time for the UK – with an ineffective Opposition, continuing calls for Scottish independence and a referendum result that gives no guidance on what kind of exit the British people want. In the second part of a lecture delivered at the Goethe University in Frankfurt on 23 November, David Kershaw warns that the UK’s constitutional arrangements, unlike those of most European countries, provide a relatively open door to populist drivers for radical change. Given the risks associated with Brexit, much weight is accordingly placed on the representative function of the Commons – but there is concern that the reliance on direct democracy has undermined it. If the Commons fails to perform this role then the


==== Cluster 0 (n=5) ====

--- DOC: University of Oxford | How AI is reshaping copyright law and what it means for the news industry | Reuters Institute for the Study of Journalism
How AI is reshaping copyright law and what it means for the news industry At the 2024 Trust Conference in London, several speakers expressed their discomfort with their intellectual property being scrapped by AI companies without any compensation, permission or credit. “We don't want to create a situation where all the [journalistic] risk is on the content producers and all the profit is on Big Tech,” said Roman Anin, founder of the Russian independent outlet iStories. Panellist Jane Barrett, Head of AI Strategy at Reuters, pointed out that existing laws could help solve this conundrum. “What I come back to is that we already have laws around copyright and IP,” she said. “Let's implement those properly first before getting into

--- DOC: University of Edinburgh | But is it art? - How AI is redrawing creativity - Edinburgh Impact
LET’s begin with the proposition that Artificial Intelligence has not yet, and never will, create an authentic work of art. Or at least not by itself. The human artists who work closest with this technology tend to be the first to say so. Canadian author Sheila Heti recently published a short story called According To Alice, written in “collaboration” with a chatbot of that name. Heti crafted text prompts to elicit odd, oblique responses from Alice that she rendered into fiction. She became “obsessed with talking to her”, even while knowing the AI had no self, no thoughts, no feeling for the joys or sufferings or mysteries of existence that compel our mortal species to write, paint, sing, and so

--- DOC: London School of Economics and Political Science | LSE100 News
18 December 2023 – Featured as part of LSE Eden Centre’s “Practice Bursts” series, LSE100 Co-Director Dr Chris Blunt shares about the LSE100 team engage students in their learning about and usage of generative AI tools. You can view Chris’s video here. Also featured as part of the “Practice Bursts” series, LSE100’s Dr Nina Vindum Rasmussen discusses her fascinating research concerning Spotify Wrapped as an algorithmic event. Nina also outlines the Spotify Unwrapped workshop format that she and her collaborator, Taylor Annabell (Utrecht University), have developed to foreground experiences of ordinary Spotify users. You can view Nina’s video here. 24 November 2023 – Today, LSE100’s Beatriz Buarque facilitated an academic workshop at the World Peace Forum Barcelona 2023, entitled ,

--- DOC: Kingâ€™s College London | Humans in the Loop | King's College London
Please note: this event has passed The King’s Festival of Artificial Intelligence presents a workshop concert of 'Humans in the Loop'. Prepare for a fast, funny, thought-provoking new musical about AI...written and performed by humans. AI helpers are getting increasingly involved in our day-to-day: a guilty secret for some, a way of life for others. But not many users know much about the hidden human beings steering the technology. Feverishly written by two flesh-and-bone humans (librettist and lyricist Lucy Bell, and composer and James Joshua Otto), before their jobs are taken by the bots, 'Humans in the Loop' is inspired by a few pressing questions: What are the long-term ambitions of tech giants? Whose personal info is feeding the machine?

--- DOC: University of Oxford | AI and media: The great flood of 2025 | Saïd Business School
Since the November 2022 launch of ChatGPT, an AI tide has risen around the media business. Existential uncertainty has seeped into storied entertainment professions, from writer to actor, executive to special effects designer. But the flood waters are also fertile with potential creative renewal and (for the C-suite) radical breakthroughs in cost-efficiency. 2025 will be the year the levee breaks. Whether the effects are good or bad depends on where you are within the media industry. Partly, this change will be via the media’s own, belated engagement. Disintermediated by the vastly bigger tech industry (chip maker NVIDIA alone is almost a 1,000 times bigger than ITV, the UK’s premier listed TV company) film, TV, music and games executives I talk


==== Cluster 1 (n=5) ====

--- DOC: University of Oxford | How generative AI chatbots responded to questions and fact-checks about the 2024 UK general election | Reuters Institute for the Study of Jo
In this piece How generative AI chatbots responded to questions and fact-checks about the 2024 UK general election In this piece Key findings | Background | Previous research | Method | Results | Conclusion | Footnotes | Appendix | References | Acknowledgements | About the AuthorsDOI: 10.60625/risj-c4vm-e367 Key findings In this factsheet, we test how well three chatbots respond to questions and fact-checks about the 2024 UK general election. Based on an analysis of 300 responses to 100 election-related questions collected from ChatGPT-4o, Google Gemini, and in the two weeks before the UK general election on 4 July 2024, we find that: - and ChatGPT-4o generally provided answers, while Google’s Gemini often refrained from answering election-related questions. - Both ChatGPT-4o

--- DOC: University of Oxford | ‘I’m unable to’: How generative AI chatbots respond when asked for the latest news | Reuters Institute for the Study of Journalism
In this piece ‘I’m unable to’: How generative AI chatbots respond when asked for the latest news In this piece Key findings | Background | Previous research | Method | Results | Conclusion | References | Funding acknowledgement | About the authorsDOI: 10.60625/risj-hbny-n953 Key findings In this factsheet we test how well two of the most widely used generative artificial intelligence (AI) chatbots – ChatGPT and Bard (now called Gemini)1 – provide the latest news to users who ask for the top five news headlines from specific outlets. We prompted each chatbot to provide headlines from the most widely used online news sources across ten countries and analysed the outputs to provide descriptive statistics on how they responded. For reasons

--- DOC: University of Oxford | Are fears about online misinformation in the US election overblown? The evidence suggests they might be | Reuters Institute for the Study of
Are fears about online misinformation in the US election overblown? The evidence suggests they might be A recent survey suggested that one-quarter of Republicans agreed that Kamala Harris is not a US citizen and that over a third of Democratic voters endorsed false statements claiming assassination attempts on Donald Trump had been staged. Run by a group of American political scientists, the Bright Line Watch survey shows that millions of Americans are prepared to say that they believe statements which are demonstrably false. But where does the blame lie? In a knife-edge US presidential election, which could be followed by a dangerous uncertainty over the results, how concerning is the influence of online misinformation including that which is sowed by

--- DOC: University of Oxford | AI, lies and conspiracy theories: How Latinos became a key target for misinformation in the US election | Reuters Institute for the Study of
AI, lies and conspiracy theories: How Latinos became a key target for misinformation in the US election Is Taylor Swift a Pentagon psychological operations asset? Did Texas governor Greg Abbott say that Joe Biden needs to learn from Vladimir Putin to work for the interest of the United States? Did Donald Trump say that the 9/11 attacks were an inside job of the US government? Has the US military arrived in Ecuador to ‘kill terrorists’? If you scroll through Spanish-language TikTok, X, and Facebook, you may have seen some of these falsehoods that aim to negatively portray Democrats or Republicans, depending on which fake news you encounter. US voters will head to the polls on 5 November in the first

--- DOC: University of Oxford | Generative AI is already helping fact-checkers. But it’s proving less useful in small languages and outside the West | Reuters Institute for
Generative AI is already helping fact-checkers. But it’s proving less useful in small languages and outside the West In a year where more than 50 countries are holding elections, bad actors are ramping up their disinformation campaigns with fake images, fake videos and fake audios created with the use of generative artificial intelligence. But just as AI is revolutionising the spread of falsehoods, could it also help debunk them? To answer that question, I spoke to three fact-checkers from Norway, Georgia, and Ghana who are applying artificial intelligence to their work. But our conversations soon turned to the limitations of this new technology when applied to diverse geographical contexts, for example in non-Western countries or in countries with underrepresented languages


==== Cluster 2 (n=5) ====

--- DOC: University of Oxford | New York Times publisher A. G. Sulzberger: “Our industry needs to think bigger” | Reuters Institute for the Study of Journalism
New York Times publisher A. G. Sulzberger: “Our industry needs to think bigger” In early January 1996 journalist Kevin McKenna presented the New York Times’ first website to three generations of the Sulzberger family: the publisher Arthur Ochs Sulzberger Jr., his father and predecessor, and his eldest son, Arthur Gregg Sulzberger, who would succeed him in 2018 and who was 15 years old at the time. McKenna was part of a four-member committee that had been working for a year on different prototypes of the website, which would go live a few days later. According to a new history of the Times by journalist Adam Nagourney, the youngest Sulzberger asked McKenna whether the new site would be updated with late-night

--- DOC: University of Oxford | Full text of A. G. Sulzberger's 2024 Reuters Memorial Lecture: Journalistic independence in a time of division | Reuters Institute for the S
Full text of A. G. Sulzberger's 2024 Reuters Memorial Lecture: Journalistic independence in a time of division It's an honour to be here to deliver this year’s memorial lecture. The Reuters Institute has been an invaluable resource for so many of us engaged in the difficult work of trying to blaze a sustainable path for quality journalism. And I feel lucky to receive such a warm welcome here at Oxford despite my institution’s many, entirely unintentional, affronts to British culture, such as our blasphemous suggestion that a full English breakfast can be cooked on a single baking tray in the oven. In the relatively short time since I was asked to speak today, the bad news about the news industry

--- DOC: University of Oxford | Changing Newsrooms 2023: Media leaders struggle to embrace diversity in full and remain cautious on AI disruption | Reuters Institute for th
In this piece Changing Newsrooms 2023: Media leaders struggle to embrace diversity in full and remain cautious on AI disruption In this piece Executive summary | 1. The impact of more flexible newsrooms on hiring, productivity, and diversity | 2. The potential impact of AI on roles and workflows | 3. Investing in culture, diversity, inclusion, and representation | Conclusions | Survey methodology | About the authors | Acknowledgements | ReferencesExecutive summary Since the first Changing Newsrooms report in 2020, this annual piece of research has aimed at exploring how news organisations around the world are adapting their working practices to external changes and internal dynamics, with a specific eye on their strategies towards attracting and nurturing talent, as well

--- DOC: University of Oxford | AI and journalism: What's next? | Reuters Institute for the Study of Journalism
AI and journalism: What's next? Innovation in journalism is back. Following a peak of activity in the mid 2010s, the idea of fundamentally reinventing how news might be produced and consumed had gradually become less fashionable, giving way to incrementalism, shallow rhetoric and in some cases even unapologetic ‘innovation exhaustion.’ No longer. The public release of ChatGPT in late November of 2022 demonstrated capabilities with such obvious and profound potential impact for journalism that AI-driven innovation is now the urgent focus of the senior leadership teams in almost every newsroom. The entire news industry is asking itself ‘what’s next’? For many people in journalism the first half of 2023 was a time for asking questions and learning the basics of

--- DOC: University of Oxford | Is ChatGPT a threat or an opportunity for journalism? Five AI experts weigh in | Reuters Institute for the Study of Journalism
Is ChatGPT a threat or an opportunity for journalism? Five AI experts weigh in Since OpenAI’s AI-powered chatbot ChatGPT was launched back in November, journalists have been discussing its potential impact on the news industry. How many journalists will be replaced by the rise of generative artificial intelligence? How fast will this process take place? Which journalists will be most vulnerable to this kind of disruption? And should we see ChatGPT as a challenge or as an opportunity to solve some of the problems the news industry faces? As all of these questions and more are hotly debated, I spoke to three experts and two startup founders to gain a clearer idea of how generative AI and large language models


==== Cluster 3 (n=5) ====

--- DOC: Kingâ€™s College London | Centre for Data Futures | King's College London
The Centre for Data Futures at King's College London is the first-ever dedicated academic centre of expertise to focus on designing and studying the effect of participatory infrastructure over the life cycle of data-reliant tools: from the point of data generation, through data empowerment structures, all the way to interface design that incentivises long-term, collective participation. This focus reflects the following conviction: if we are to be the authors of a variety of socially sustainable, data-reliant futures, data needs to become a tool for bottom-up socio-economic and political empowerment. Our team Themes Data Empowerment Data empowerment initiatives enable communities to gain agency over how their data is used and for what purpose, thereby reversing the habit of passivity encouraged by

--- DOC: Imperial College London | Breaking the bias: I-X celebrates women in AI | Imperial News | Imperial College London
To mark International Women's Day and Women at Imperial Week, we spoke to twelve of our female I-X experts about the impact of AI on gender equality. As AI systems become ubiquitous in everyday life, how can we ensure pre-existing inequalities are not exacerbated? With only 22 per cent of women working in AI and data professions in the UK, we asked women across our I-X community to reflect on how we could attract more women to the field of AI, the potential it may have in advancing gender equality and ways to prevent bias in these technologies. Dr Alessandra Russo Professor in Applied Computational Logic "Recent advances in AI, if deployed in a fair and responsible manner, offer great

--- DOC: Technical University of Munich | Challenges › hackaTUM
CHECK24 Fast & Flawless: Optimize Your Way to Victory Put your coding skills to the test in CHECK24’s unparalleled challenge at hackaTUM! Your mission: build a lightning-fast rental car comparison tool (Mietwagenvergleich) that outperforms the competition. Form a team of 2-4 and compete to optimize your response time for extreme loads and high concurreny. With automated tests and a live leaderboard updating in real-time, only one team can claim the top spot. Are you ready to accelerate your way to victory? Huawei Fortified on all fronts Operating system security is a multi-faceted area of research covering a wide collection of topics. Therefore, our challenge is a combination of smaller problems from multiple aspects of OS Security and Engineering, which allows

--- DOC: University of Edinburgh | Digital Research Ambassadors
Digital Research Ambassadors is a fully funded internship scheme benefiting postgraduate research students and research groups/professional staff across the University. It is developed and supported by Digital Research Services and has been running since 2019. Interns - postgraduate students with strong data and computing skills - are matched with host projects across the University. They will bring in digital research expertise, contributing to skill development and project planning. They also gain hands-on interdisciplinary research experience. Hosts - research or professional staff across the University - propose a project and will receive support from the intern. They will gain new perspectives and hands-on support in using digital tools and services, develop additional dimensions to digital research planning and inspire a new

--- DOC: Kingâ€™s College London | Digital Futures Institute announces four Institute Fellowship projects for 2024-25 | King's College London
‘I'm delighted to welcome our new cohort of Fellows. Their collective work showcases an inspiring range of initiatives that interrogate our relationship with technology. They will benefit from the support and expertise within the Institute, and we will benefit from their expertise. I'm looking forward to seeing their work progress.’ Professor Marion Thain, Chair-Director of the Digital Futures Institute 04 June 2024 Digital Futures Institute announces four Institute Fellowship projects for 2024-25 Four interdisciplinary projects awarded Institute Fellowships from the Digital Futures Institute for the 2024-25 cohort, each of which is led by a pair of colleagues who bring together SHAPE and STEM expertise. Eight projects have been funded by the Digital Futures Institute with a Principal Investigator (PI) and


==== Cluster 4 (n=5) ====

--- DOC: Kingâ€™s College London | Centre for International Governance and Dispute Resolution (CIGAD) | King's College London
From interstate conflict to the threat of the climate crisis, the world faces challenges that require an unprecedented level of cooperation and a strong system of international governance to resolve. Yet the system of international governance established after World War II is in turmoil. International institutions are increasingly deadlocked or dysfunctional, and our rules-based system is under attack. Conflict proliferates and systems of dispute resolution must adapt. The Centre for International Governance and Dispute Resolution (CIGAD) at The Dickson Poon School of Law brings together academics, policymakers and practitioners working in the areas of international law and dispute resolution to help tackle these global challenges. The Centre works with a growing network of global partners in collaborative research projects. We

--- DOC: London School of Economics and Political Science | Limiting Sovereignty and Legitimising Intervention - LSE Human Rights
By Nora Jaber* International law’s elevated focus on the protection of human rights has resulted in a shift from a purely state-centered body of law to one that is increasingly focused on individual rights. This has been accompanied by a shift away from the concept of sovereignty as protection against external interference, to one of sovereignty as responsibility. According to Anne Peters, sovereignty can no longer be regarded as the “first principle” of international law; rather “it should be seen to exist only in function of humanity.” While this is desirable, this article argues that it presents a rather utopian and unrealistic understanding of international law as it is currently formulated. To what extent has sovereignty been limited by human

--- DOC: London School of Economics and Political Science | LawGPT? How AI is Reshaping the Legal Profession - Impact of Social Sciences
Generative AI is causing many fields of expert and professional knowledge to reassess fundamental practices and their value. Taking law, a field that has long been warned of potential threats of automation, as a focus, Giulia Gentile outlines the socio-technical challenges facing the discipline and considers how new technology may rebalance relationships between lawyers, technologists and clients. We are still wrapping our heads around the potential impact of AI in our society. No fields seem to be immune from the influence of AI, including the legal profession broadly understood. Lawyers, clerks and legal advisors across the world are all exploring the implications of AI. Two different questions are currently occupying legal professionals when it comes to AI, showcasing the Janus-faced

--- DOC: University of Oxford | Reassessing the Autonomy Principle in Trade Finance: Lessons from Civil Law Jurisdictions | Oxford Law Blogs
Reassessing the Autonomy Principle in Trade Finance: Lessons from Civil Law Jurisdictions The principle of autonomy has long served as a cornerstone of trade finance, offering commercial certainty and speed in instruments like letters of credit and demand guarantees. However, English law’s rigid application of this principle, particularly the strict limits on judicial intervention, no longer reflects the commercial realities of digital trade or the operational dynamics of cross-border enforcement. Courts currently intervene only in cases of clear and established fraud, a threshold that is rarely met in time-sensitive transactions. A more balanced model, guided by civil law insights, may better preserve legitimacy and efficiency in modern trade finance. Banks typically assess compliance based on facial conformity, consistent with practices

--- DOC: University of Oxford | Call for Papers and Workshop Report: 2nd ‘The Future of Business Law: Diversifying Voices and Perspectives’ Workshop (2025) | Oxford Law Blo
Call for Papers and Workshop Report: 2nd ‘The Future of Business Law: Diversifying Voices and Perspectives’ Workshop (2025) On Friday, 25 April 2025, the University of Leeds School of Law’s Centre for Business Law and Practice (CBLP) will host the 2nd edition of the workshop ‘The Future of Business Law: Diversifying Voices and Perspectives’. The 1st workshop in this series was hosted by Durham University’s Institute for Commercial and Corporate Law on 1 May 2024. The Call for Papers and Expressions of Interest for the 2nd workshop can be found here. Those interested in responding to the Call for Papers and Expressions of Interest, or in otherwise participating in the 2nd Future of Business Law workshop are invited to read


==== Cluster 5 (n=5) ====

--- DOC: University of Cambridge | In memoriam: HE Judge James Crawford AC SC FBA | Lauterpacht Centre for International Law
Judge James Richard Crawford AC SC FBA, Whewell Professor of International Law at the University of Cambridge (1992-2015), Fellow of Jesus College, and Director of the Lauterpacht Centre for International Law (1997-2003, 2006-2010) passed away on 31 May 2021. A legend of international law, James was also a towering figure on the Cambridge landscape. He was doctoral supervisor to more than 70 students, a mentor and friend to hundreds of students, fellows and visiting fellows, and an inspiration to countless others. At the Centre, we knew him also as an avid reader of history, connoisseur of music, art, food and wine, an excellent host, a great cricket fan, a writer of poetry on international law, and a man of great

--- DOC: London School of Economics and Political Science | Mooting
Mooting at LSE Mooting has a proud tradition in the LSE Law School, with LSE students participating in several major academic moots every year, including the Philip C. Jessup International Law Moot Court Competition, the Willem C. Vis International Commercial Arbitration Moot, the Oxford International Intellectual Property Law Moot, the ESU-Essex Court Chambers National Mooting Competition, the Atkin Chambers Commercial Law Moot, and more. LSE is also the host of the LSE-Featherstone LGBT+ Moot. The LSE Students Union is very active in mooting, via the LSE Bar & Chambers division of the LSE Law Society. For 2022-23 the LSE Law School’s Academic Director of Mooting is Dr Luke McDonagh, who can be contacted at l.t.mcdonagh@ LSE Schools Mooting Competition During

--- DOC: Kingâ€™s College London | King's Legal Clinic evaluates impact of successful cross-cultural module in India visit | King's College London
The reason we partnered with this project is the persuasive power of the lawyer. The students who visited won over the trust of the local community. This work is not just helping the Sundarbans, we are helping everyone. The river belongs to all. Subimal Da, Community Leader from Chetana Sangat 11 October 2023 King's Legal Clinic evaluates impact of successful cross-cultural module in India visit A year since the King’s Legal Clinic launched the Transitional Remedies in Environmental Harm module, the King's Legal Clinic and their Indian partners met in Kolkata to evaluate the impact of the cross-collaborative module. Sue Wilman, Assistant Director of the Legal Clinic, went to Kolkata to meet with academics from the Indian universities, West Bengal

--- DOC: Kingâ€™s College London | Postgraduate scholarship opportunities | Website archive | King’s College London
Postgraduate scholarship opportunities The Dickson Poon School of Law would like to proudly announce its new postgraduate scholarships, including 16 full LLM scholarships. The Yeoh Tiong Lay LLM Law Scholarship Programme The Yeoh Tiong Lay LLM Scholarship Programme offers prestigious scholarships to outstanding new Law students starting their studies at The Dickson Poon School of Law, King’s College London. The scholarships form part of a larger £7 million gift to set up a new research-based Centre for Politics, Philosophy & Law. The gift, from the family of Malaysian alumnus Dato' Mark Yeoh, will further build King’s reputation as a dynamic international centre for legal teaching and research in the heart of London. The £7 million gift is establishling, through endowment,

--- DOC: Kingâ€™s College London | Professor Gillian Douglas | King's College London
Professor Gillian Douglas Professor of Law - Emeritus Executive Dean, The Dickson Poon School of Law Research interests - Law Contact details Biography Gillian Douglas has an LLB from Manchester University and gained an LLM at the London School of Economics. In 2011 she was awarded the degree of LLD (Doctor of Laws) by Cardiff University. She has taught at the University of Bristol, the National University of Singapore and Cardiff University, where she served as Head of the School between 2005 – 2010. She is a past Secretary-General of the International Society of Family tween 2010-2014, she was Chair of the Law Sub-Panel for REF 2014 and has served as a member of the AHRC's Peer Review College and


==== Cluster 6 (n=5) ====

--- DOC: University of Cambridge | The Hall of Fame | Department of Computer Science and Technology
The Hall of Fame celebrates the companies started by Computer Science and Technology graduates and staff If you would like to add a company to the list, please complete this form. If you have any corrections to this list, please sent them to ring-organiser@. Current number of companies: 356 - Acorn Computer Co-founder: Andy Hopper Founded in 1979, Acorn produced a number of computers including the BBC Micro. - Active Media Solutions Founders: John Bates and Giles Nelson Founded in 1995, Active Media Solutions was one of the first companies to deploy complex database-driven websites in which information can be easily classified and searched rather than statically encoded as HTML. - Actuarial Solutions Ltd Founder Martin Barringer Founded in 1999,

--- DOC: University of Cambridge | University Venture Fund – Cambridge Enterprise
Our Funds: University Venture Fund Since 1995, we have managed investments made by the University Venture Fund into new companies. This is an evergreen fund, investing ring-fenced University capital, and because all returns are reinvested, each new Cambridge innovation supports the next. The University invested a further £30 million into the University Venture Fund in 2020, with £10 million committed to sustainability investments. The fund holds current key investments in Riverlane, Nu Quantum, and T- Therapeutics as well as investments in companies in our sustainability portfolio including Cambridge Electric Cement, Carbon Re, Nyobolt and Seprify, demonstating the importance of impact these businesses have on the wider world. 52 North 52 North is reinventing the healthcare journey, creating affordable, cutting-edge technology

--- DOC: Imperial College London | Wave energy startup wins Imperial’s Venture Catalyst Challenge 2023 | Imperial News | Imperial College London
A startup developing wave energy converters that can be embedded under the seabed has been named as one of Imperial’s most promising new businesses. WaveX won the Venture Catalyst Challenge 2023 for developing an innovative solution for making wave energy more reliable and less expensive. The startup was founded by Mechanical Engineering graduate Thomas Allen, Environmental graduate Will Evans, PhD student Jacob Francis, alongside Clement Puech and Olivier Bourdin. Now in its tenth year, the Venture Catalyst Challenge (VCC) is the College’s largest entrepreneurial competition for students and alumni, providing support for innovators to develop their ideas for commercialisation. WaveX took home a total prize of £30,000 after competing against four other startups in the VCC Grand Final. This year's

--- DOC: University of Edinburgh | Edinburgh secures £24 million boost for AI innovation | News | The University of Edinburgh
Innovative AI Using AI to develop more efficient semiconductors, design more complex microchips, and improve the early prediction of debilitating diseases are some of the potential outcomes of the £24m funding from the Engineering and Physical Sciences Research Council (EPSRC). Of the nine centres announced as part of EPSRC’s £80m UK-wide investment in applying AI to real world data and research, Edinburgh will lead or be involved in more than half, further cementing its place as a driving force in the development of AI in the UK. Edinburgh hubs The AI Hub for Productive Research and Innovation in Electronics (APRIL) will seek to bring the benefits of AI to the UK electronics industry. APRIL will develop AI tools to accelerate

--- DOC: Imperial College London | WE Innovate: Imperial’s top women-led ventures to showcase groundbreaking ideas | Imperial News | Imperial College London
Five exciting new businesses will compete for a £30,000 prize fund in the final of Imperial’s flagship programme for women-led startups. This year’s finalists for WE Innovate are developing new technologies to make the world a better place, with innovative ideas for improving IVF treatment, the security of live events, and the diagnosis of debilitating knee conditions. The WE Innovate programme, run by Imperial Enterprise Lab, is a targeted pre-accelerator open to teams led by students, recent alumni and Early Career Researchers who identify as women. WE Innovate supports women founders through a six-month programme of masterclasses, business coaching, 1-to-1 expert support, and peer mentoring, with the top five teams competing for a chance to win a share of a


==== Cluster 7 (n=5) ====

--- DOC: University of Edinburgh | Matthew L McDowell BA PhD FRHistS | The University of Edinburgh
Matthew L McDowell BA PhD FRHistS Lecturer in Sport Policy, Management, and International Development - Moray House School of Education and Sport, ISPEHS - University of Edinburgh Contact details Address - Street - Moray House School of Education and Sport, St Leonard's Land, Room 4.26 - City - University of Edinburgh (Holyrood Campus) - Post code - EH8 8AQ Background I am an historian of sport, leisure, and tourism, and I have spent over twelve years at Moray House. Previously, I was employed by Glasgow and Kingston Universities as a tutor and sessional lecturer, where I taught on a variety of undergraduate and postgraduate courses in history, Scottish studies, and sport studies. I have also previously taken part in an

--- DOC: University of Oxford | Statistics Bulletin, Monday 5 May 2025 | Oxford statistics department - University of Oxford
Term Theme - Wellbeing Physical Wellbeing Wellbeing is influenced by all aspects of your life, including your physical health. Our jobs can sometimes mean that we spend hours sitting at a desk, hardly moving. Below are some resources you can use to improve your physical health. If you want to do something today, why not take a walk in University Parks at lunch? NHS Resources The NHS has a plethora of resources to help you gain the best physical health. NHS Better Health provides guidance on how to lose weight, quit smoking, get active and drink less. NHS Live Well also provides advice on healthy living, including eating healthily and sleeping well. There are guidelines to exercising and exercise videos

--- DOC: Kingâ€™s College London | Andrew Wright | King's College London
Mr Andrew Wright Associate Director (Employer Engagement & Work-based Learning) - Employer Lead for North America & Brussels - AGCAS Professional Standards Committee - Institute of Student Employers (ISE) Research & Policy Steering Group - Institute of Student Employers (ISE) Universities Steering Group Research interests - Employers - Employment Pronouns He/Him Biography As Associate Director (Employer Engagement & Work-based Learning), Andrew has overall responsibility for the strategic and operational running of King's employer connectivity, its global employer reputation, and its relationship with all stakeholders, including employers, suppliers, alumni and donors. He is also a member of King's Education & Students Leadership Team. Andrew leads the planning, development and oversight of King's entire Employer Engagement function including employer relations and business

--- DOC: University of Cambridge | Leadership, learning and development – your MBA year beyond academics - News & insight - Cambridge Judge Business School
Special Interest Groups Formed and run by MBA and MFin students, special interest groups – or SIGs – are an integral part of the Cambridge Judge experience. They offer a chance to network and share ideas around a particular area. Current examples range from Finance and Entrepreneurship to Sustainability and Social Impact. Many SIGs arrange their own conferences and talks and offer opportunities to take on key leadership roles. Students who engage with, or lead and organise a special interest group during their time at Cambridge, often experience numerous benefits. These experiences allow them to further develop and apply their leadership and communication skills, which are essential components of the Cambridge MBA programme. In November, at the start of the

--- DOC: University of Cambridge | Core courses and electives - The Cambridge MBA - Cambridge Judge Business School
Establish secure foundations on which the rest of your career will be built. This course is designed to give you an economic perspective on the topics, concepts and analytical tools that you will encounter in other parts of the MBA. You will be introduced to the parts of microeconomics that are especially relevant to management. Understanding how individuals behave and the relationship between individual and group behaviour and organisational performance are some of the most challenging issues for managers and professionals. This course is designed to increase your knowledge about behaviour and performance within organisations and how these can be influenced and managed. This course covers the evaluation and funding of investments. The aim of the course is to develop


==== Cluster 8 (n=5) ====

--- DOC: University of Oxford | What do Large Language Models tell us about ourselves? | Ethics in AI
(Image credit: this image was generated by asking ChatGPT 4o to do so. The authors have made a donation to Modern Art Oxford upon publishing this post. No LLMs were used in writing the text of this post.) What large language models are able to do can teach us valuable lessons about our own mental lives. By Professor Yoshua Bengio & Professor Vincent Conitzer When we evaluate AI on a task, we often use “human-level performance” as a benchmark. There are several advantages to that. For one, it is a standard that is intuitively easy to appreciate. Also, if we create an AI system that clearly exceeds what any human can do, then we can be sure that the AI

--- DOC: University of Oxford | Natural Language Processing — Publications - OATML
Natural Language Processing — Publications Uncertainty-Aware Step-wise Verification with Generative Reward Models Complex multi-step reasoning tasks, such as solving mathematical problems, remain challenging for large language models (LLMs). While outcome supervision is commonly used, process supervision via process reward models (PRMs) provides intermediate rewards to verify step-wise correctness in solution traces. However, as proxies for human judgement, PRMs suffer from reliability issues, including susceptibility to reward hacking. In this work, we propose leveraging uncertainty quantification (UQ) to enhance the reliability of step-wise verification with generative reward models for mathematical reasoning tasks. We introduce CoT Entropy, a novel UQ method that outperforms existing approaches in quantifying a PRM’s uncertainty in step-wise verification. Our results demonstrate that incorporating uncertainty estimates improves the

--- DOC: University of Oxford | Detecting hallucinations in large language models using semantic entropy - OATML
Detecting hallucinations in large language models using semantic entropy Blog post accompanying Detecting Hallucinations in Large Language Models Using Semantic Entropy in Nature. Large language models (LLMs) can do many things well. But their generations are often unreliable. Sometimes this manifests as a lawyer using ChatGPT to look up legal precedents that are totally made up. Even more seriously, it could mean medical errors. Ideally, there would be ways to start to tackle the “hallucination” problem for LLMs. In our recent paper in Nature, we make some progress. What is hallucination? The first step is to get a bit more precise. The word “hallucination” for LLMs has expanded to include almost every kind of being wrong. But there is no

--- DOC: London School of Economics and Political Science | Can generative AI add anything to academic peer review? - Impact of Social Sciences
Generative AI applications promise efficiency and can benefit the peer review process. But given their shortcomings and our limited knowledge of their innerworkings, Mohammad Hosseini and Serge P.J.M. Horbach argue they should not be used independently nor indiscriminately across all settings. Focusing on recent developments, they suggest the grant peer review process is among contexts that generative AI should be used very carefully, if at all. Readers can find more posts on Peer Review and the Impact of AI on Higher Education via the links. In the ever-evolving landscape of academic research and scholarly communication, the advent of generative AI and large language models (LLMs) like OpenAI’s ChatGPT has sparked attention, praise and criticism. The use of generative AI for

--- DOC: London School of Economics and Political Science | Using GenAI for the REF is a no-brainer - Impact of Social Sciences
There is a growing interest in how Generative AI can be used to support and streamline research assessment processes. Richard Watermeyer and Lawrie Phipps argue the standardisation and formulaic nature of REF assessment, alongside its cost, make it a prime candidate for where generative AI could relieve academic drudge work. The academic research community is gearing itself up for yet another instalment of the Research Excellence Framework (REF). For the likely few uninitiated readers of this blog and for those in need of reminder, the REF is the means by which the UK Government distributes somewhere in the region of £2billion of annual quality-related research funds to higher education providers able to evidence research ‘excellence’. Occurring roughly every 6-8 years,


==== Cluster 9 (n=5) ====

--- DOC: London School of Economics and Political Science | How the most recent AI wave affects jobs - LSE Business Review
With rapid progress in natural language processing and image generation, AI now affects creative occupations, which were previously considered safe from automation. Cecily Josten and Grace Lordan write that job displacement concerns are legitimate and new approaches to education and workforce development are needed. They say that addressing biases in AI and fostering reskilling are also necessary for inclusive adaptation to AI advancements. Artificial intelligence (AI) has been a widely debated topic of the past decades with new AI waves following previous ones rapidly. At work, AI has already replaced occupations and tasks within occupations, and will likely continue to do so (Frey and Osborne 2013). But for a long time, many experts argued that AI and automation more generally

--- DOC: University of Oxford | OII | The Winners and Losers of Generative AI in the Freelance Job Market
The Winners and Losers of Generative AI in the Freelance Job Market Published on 29 Jan 2025 A new study led by an international research team, including Dr Fabian Braesemann from the Oxford Internet Institute, part of the University of Oxford, shows how Generative AI tools like ChatGPT are reshaping the workforce. A new study led by an international research team, including Dr Fabian Braesemann from the Oxford Internet Institute, part of the University of Oxford, shows how Generative AI tools like ChatGPT are reshaping the workforce. The research, published on 29 January 2025 in the Journal of Economic Behavior & Organization, analyses over three million job postings on a global freelancing platform, making it the largest study of its

--- DOC: University of Oxford | Expert Comment: Jobs will be automated, but not because of the latest Generative AI | University of Oxford
Expert Comment: Jobs will be automated, but not because of the latest Generative AI Everyone is worried about Artificial Intelligence. From writers in Hollywood to computer programmers, recent advances in technology are causing concern about what Generative AI is going to mean for the future of work, our society and the wider world. Is there nothing machines will not be able to do? By Professor Carl-Benedikt Frey, Dieter Schwarz Associate Professor of AI & Work, Oxford Internet Institute & Director, Future of Work Programme, Oxford Martin School, and Professor Michael Osborne, Professor of Machine Learning, Department of Engineering Science and co-Director, Oxford Martin AI Governance Initiative. We have spent a decade researching the impacts of AI. Ten years ago, we

--- DOC: University of Oxford | Jobs will be automated, but not because of the… | Oxford Martin School
Everyone is worried about Artificial Intelligence. From writers in Hollywood to computer programmers, recent advances in technology are causing concern about what Generative AI is going to mean for the future of work, our society and the wider world. Is there nothing machines will not be able to do? We have spent a decade researching the impacts of AI. Ten years ago, we wrote a paper estimating that some 47% of US-based jobs could be automated in principle, as AI and mobile robotics expanded the scope of tasks that computers can do. Our estimates were based on the premise that, while computers might eventually be able to do most tasks, humans would continue to hold the comparative advantage in three

--- DOC: London School of Economics and Political Science | AI and automation can open the way for workplace inclusion - LSE Business Review
With the rapid advancements in technology, the fear of job loss is palpable. But is this the whole truth for artificial intelligence and automation? Jasmine Virhia and Ariela Kleinberg Shveid write that these technologies can potentially bring a big benefit to workers: enhanced workplace inclusion. The city of Tokyo gained a robot-run restaurant in 2021. Upon hearing this, you would be justified in asking, “how does this help our current population or create more jobs, when you could have human cashiers, bartenders, and waiters?” The catch with the Dawn Avatar Robot Cafe is that it is run by people with disabilities, who are otherwise unable to work. In the process of using robots, this café not only created new jobs


==== Cluster 10 (n=5) ====

--- DOC: London School of Economics and Political Science | Nick Couldry: Using AI for trivial tasks hurts the planet - LSE Business Review
Data centres around the world consume vast amounts of electricity and water. In London, Thames Water has expressed great concern with possible shortages. Nick Couldry believes that we must stop using AI for trivial tasks every day. Without this behavioural change, we risk worsening climate change. He discussed the environmental consequences of AI in this Q&A with Anna Bevan for LSE’s IQ Podcast. Why are data centres so problematic for the environment? It’s primarily the electricity usage. Computer chips require vast amounts of power to run calculations. Some countries—such as Ireland—are using a high percentage of their national electricity on data centres. India is also heavily affected. In Northern Virginia, near Washington, DC, there’s one of the world’s largest collections

--- DOC: University of Oxford | Generative AI and carbon emissions in the Oxford context | Staff Gateway
Generative AI and carbon emissions in the Oxford context The Digital Transformation team explore the ongoing debate about generative AI and the environment The growing use of generative AI tools has sparked questions about its environmental impact at Oxford and beyond. This article by the Digital Transformation team explores the ongoing debate about this subject, and how the University is responding. As the widespread adoption of generative AI continues, there is an increasing focus on its environmental impact. Questions include: - Are we increasing our carbon footprint by using AI tools? - Is it possible to balance innovation with our commitments to net zero and sustainability? - What can we do to minimise the impact of the technology? There are

--- DOC: University of Cambridge | Is ChatGPT bad for the environment? - Bennett Institute for Public Policy
While concerns about the energy and water demands of AI aren't entirely misplaced, much of the public debate misses crucial context. Rather than focusing on individual generative AI use, more transparency is needed from AI companies on the climate impact of developing their models, writes Sam Gilbert. Should we be worried about the climate impact of our generative AI use? Read the news, and you would certainly think so. It’s been widely reported that messaging ChatGPT requires ten times as much electricity as a Google search, and that a full conversation consumes a 500ml bottle of water. Often, a straight line is drawn between statistics like these and reports that AI data centres are putting grids under strain, delaying the

--- DOC: University of Cambridge | Sustainable real estate - a constellation of risks and opportunities | Cambridge Institute for Sustainability Leadership (CISL)
29 August 2023: First published in The Lighthouse, BNP Paribas REIM’s European Property Market Outlook, this blog by Munish Datta explores the constellation of risks and opportunities for sustainable real estate. Here, Lucy Bruzzone provides reflections and recommendations on ‘what next?’. Real estate absolutely underpins human society. It provides us with habitation, a place to gather, rest, learn, play, heal and work – in fact we spend most of our lives in buildings. However, for a sector that covers 1% of the world’s land, it has a hugely disproportional environmental footprint: 40% of global carbon emissions, 50% of all extracted materials, 33% water consumption and 35% of generated waste. As our planet’s finite resources become scarcer, user demand changes rapidly,

--- DOC: London School of Economics and Political Science | If AI uses a lot of energy and you care about the climate, should you be anti-AI? - LSE Business Review
Artificial intelligence consumes an inordinate amount of energy, but voluntary restraint is hardly a solution to preserve the environment. AI can be used instead to find technological solutions. Alessio Terzi writes that rather than opting for outright bans on the construction of new data centres, clear incentive structures should be put in place to steer AI innovation towards solutions that are both sustainable and commercially viable. The techno-optimism surrounding the surge of artificial intelligence (AI) is palpable. Enter, however, a classroom of sustainability master’s students, as I regularly do, and you will hear voices of complaint against what is perceived as a massively energy-intensive Silicon Valley toy with limited tangible upside for humanity’s pressing social and environmental challenges. Recent reports


==== Cluster 11 (n=5) ====

--- DOC: UCL | 2024 Projects | UCL Centre for Medical Image Computing - UCL – University College London
MedICSS includes interactive sessions throughout the week, including group mini projects. - Deep Learning for Neurodegenerative Disease Classification using Multimodality MRI Imaging Lead person: Moona Mazher (Postdoc Research Fellow) Co-leads: Elinor Thompson (Postdoc Research Fellow) Description: Nowadays, one of the most successful modern deep-learning applications in medical imaging is image classification. Disease classification in medical imaging is of significant importance due to its potential impact on patient care, diagnosis, treatment planning, and overall healthcare delivery. Early detection of diseases is often critical for effective treatment and improved patient outcomes. Medical imaging techniques, such as MRI, allow healthcare professionals to identify abnormalities at an early stage, leading to timely interventions. Similarly, accurate disease classification aids in formulating appropriate treatment plans. Neurodegenerative

--- DOC: University of Oxford | Deep Medicine — Nuffield Department of Women's & Reproductive Health
Seeking Insights into Disease Patterns, Risks & Treatment Effects WRH Research Group operating within our department's Data Science theme, lead by Prof. Kazem Rahimi Deep Medicine Deep Medicine takes advantage of large datasets, pioneering and established data science approaches, and digital trials to identify solutions that will help tackle some of the major causes of death and disability in the UK and worldwide. The insights generated by the Deep Medicine team enable clinicians and health service providers to predict the risk of developing chronic disease, better assess its consequences, and identify the best management practices and interventions to improve health outcomes. Why is the project important? Recent advances in medicine have led to an unprecedented increase in life expectancy, but

--- DOC: University of Cambridge | Brain charts
Brain charts Mapping the rapid growth and slow decline of the human brain over our lifetime An international team of researchers has created a series of brain charts spanning our entire lifespan – from a 15 week old fetus to 100 year old adult – that show how our brains expand rapidly in early life and slowly shrink as we age. The charts are the result of a research project spanning six continents and bringing together possibly the largest ever MRI datasets ever aggregated – almost 125,000 brain scans from over a 100 different studies. Although not currently intended for clinical use, the team hopes the charts will become a routine clinical tool similar to how standardised paediatric growth charts

--- DOC: Kingâ€™s College London | Researchers investigate ability of their new AI tool to predict medical events | King's College London
Our study shows that Foresight can achieve high levels of precision in predicting health trajectories of patients, demonstrating it could be a valuable tool to aid decision making and inform clinical research. The proposed purpose of Foresight is not to enable patients to self-diagnose or predict their future, but it could potentially be used as an aid by clinicians to make sure a diagnosis is not missed or for continual patient monitoring for real-time risk prediction. One of the main advantages of Foresight that it can easily scale to more patients, hospital or disorders with minimal or no modifications, and the more data it receives the better it gets. Zeljko Kraljevic, first author and Research Fellow in Health Informatics at

--- DOC: UCL | Phenopolis Ltd – Presents TrialSense the world’s most advanced Clinical Trial Management System | UCL Centre for Digital Innovation - UCL – 
Phenopolis Ltd – Presents TrialSense the world’s most advanced Clinical Trial Management System Phenopolis Ltd, a UCL HealthTech spinout, joined cohort 5 to enhance and expand their groundbreaking digital solution, TrialSense, setting a new standard in the clinical trial landscape. 22 July 2024 Phenopolis specialises in building transformative health-tech web applications that comply with regulatory standards, within a secure, distributed, cloud-based environment. Founded in 2018 by Ismail Moghul, a PhD student at the UCL Cancer Institute and Dr Nikolas Pontikos, a postdoc from the UCL Institute of Ophthalmology, Phenopolis recently joined cohort five of the CDI Impact Accelerator to advance and scale up their innovative digital solution, TrialSense. TrialSense seamlessly integrates diverse clinical trial data, including imaging, genomics as well


==== Cluster 12 (n=5) ====

--- DOC: University of Edinburgh | Wikipedia at 24: Wikipedia and Artificial Intelligence – Wikimedian in Residence
Wikipedia at 24 “With more than 250 million views each day, Wikipedia is an invaluable educational resource”.[1] In light of Wikipedia turning 24 years this (January 15th), and the Wikimedia residency at the University of Edinburgh turning 9 years old this week too, this post is to examine where we are with Wikipedia today in light of artificial intelligence and the ‘existential threat’ it poses to our knowledge ecosystem. Or not. We’ll see. NB: This post is especially timely given also Keir Starmer’s focus on “unleashing Artificial Intelligence across the UK” on Monday[2][3] and our Principal’s championing of the University of Edinburgh as “a global centre for artificial intelligence excellence, with an emphasis on using AI for public good” this

--- DOC: London School of Economics and Political Science | Approach Generative AI Tools Proactively or Risk Bypassing the Learning Process in Higher Education | LSE Public Policy Review
Introduction The rise of Generative AI (GenAI) tools and their impact on teaching, learning, and assessment practices has become a significant topic of discussion in higher education (1, 2). Since November 2022, when OpenAI introduced ChatGPT, its online conversational AI chatbot, educators and students have been challenged by the capabilities of this new category of tools which includes similar systems from rival tech companies such as Google’s Gemini, GitHub’s Copilot, Microsoft’s Copilot, and Anthropic’s Claude. For the first time, people could easily converse directly on almost any topic with an AI chatbot using natural language to discuss and ‘look up’ information instead of retrieving it from search engines, Wikipedia, academic databases, or primary sources (3). Some GenAI-powered tools also function

--- DOC: University of Oxford | Yarin Gal - OATML
Back to all members... Yarin Gal Associate Professor Yarin leads the Oxford Applied and Theoretical Machine Learning (OATML) group. He is an Associate Professor of Machine Learning at the Computer Science department, University of Oxford. He is also the Tutorial Fellow in Computer Science at Christ Church, Oxford, a Turing AI Fellow at the Turing Institute, and Director of Research at the UK Government’s AI Security Institute (AISI, formerly the Frontier AI Taskforce). Prior to his move to Oxford he was a Research Fellow in Computer Science at St Catharine’s College at the University of Cambridge. He obtained his PhD from the Cambridge machine learning group, working with Prof Zoubin Ghahramani and funded by the Google Europe Doctoral Fellowship. Yarin

--- DOC: University of Oxford | Guest Post: It has become possible to use cutting-edge AI language models to generate convincing high school and undergraduate essays. Here’
Written by: Julian Koplin & Joshua Hatherley, Monash University ChatGPT is a variant of the GPT-3 language model developed by OpenAI. It is designed to generate human-like text in response to prompts given by users. As with any language model, ChatGPT is a tool that can be used for a variety of purposes, including academic research and writing. However, it is important to consider the ethical implications of using such a tool in academic contexts. The use of ChatGPT, or other large language models, to generate undergraduate essays raises a number of ethical considerations. One of the most significant concerns is the issue of academic integrity and plagiarism. One concern is the potential for ChatGPT or similar language models to

--- DOC: University of Oxford | Aidan Gomez - OATML
Back to all members... Aidan Gomez PhD (2018—2023) Aidan was a doctoral student of Yarin Gal and Yee Whye Teh at The University of Oxford. He founded Cohere and a research group called , focussing on providing resources, mentorship, and facilitating collaboration between academia and industry. Aidan’s research deals in understanding and improving neural networks and their applications. Previously, he worked with Geoffrey Hinton and Łukasz Kaiser on the Google Brain team. He obtained his Bachelors from The University of Toronto with supervision from Roger Grosse. He is an AI Fellow for Open Philanthropy and a Clarendon Scholar. Publications while at OATML • News items mentioning Aidan Gomez • Reproducibility and Code • Blog Posts Publications while at OATML: Interlocking


==== Cluster 13 (n=5) ====

--- DOC: UCL | Is AI killing the internet? | Faculty of Engineering
Is AI killing the internet? What impact does AI have in our society? What about ethical concerns in healthcare? What's AI's role in art and governance? In this episode, we discuss the impact of artificial intelligence (AI) on society with Stephen Hughes, a social scientist, and Reese Campbell, a freelance project coordinator. Stephen explores the mixed public sentiment towards AI, highlighting its benefits in healthcare and concerns about its ethical implications, particularly in mental health services. Reese shares her negative views on AI, citing deepfakes and privacy violations. They also discuss AI's potential to exacerbate social inequalities and the role of AI in the art world. The conversation concludes with reflections on the future of AI and its governance. Stephen

--- DOC: LMU Munich | What AI can really do - LMU Munich
What AI can really do 9 Dec 2024 Where is artificial intelligence heading? LMU researchers on the use and limitations of the technology in medicine, business, and society. 9 Dec 2024 Where is artificial intelligence heading? LMU researchers on the use and limitations of the technology in medicine, business, and society. Artificial intelligence (AI) is a key technology in that it enables a wide range of applications. It is already part of our everyday lives: it is the technology behind translation tools and chatbots and is used in areas like medicine. What are the challenges associated with AI? What aspects are important for the technology’s further development? Scientists from various disciplines across LMU shed some light on the following issues

--- DOC: University of Oxford | Expert comment: Oxford AI experts comment on the outcomes of the UK AI Safety Summit | University of Oxford
Expert comment: Oxford AI experts comment on the outcomes of the UK AI Safety Summit Over 2 days, the UK AI Safety Summit brought together approximately 150 representatives from across the globe including government leaders and ministers, and industry, academia and civil society leaders. Oxford academics comment on the outcomes. Ciaran Martin is Professor of Practice in the Management of Public Organisations, University of Oxford. “It’s easy to criticise, but don’t let the perfect be the enemy of the good. This was a good initiative and the British Government deserves credit for its global leadership. The alternative was not a better event – the alternative was nothing at all, and a repeat of the mistakes of a generation ago when

--- DOC: University of Oxford | Dr Caroline Green is keeping social care human in the age of AI | University of Oxford
Dr Caroline Green is keeping social care human in the age of AI AI ethics not only concerns philosophers, computer scientists, policy makers or lawyers - AI is increasingly part of people's lives. We must ensure that it's developed, rolled out and used responsibly; in a way that does not reinforce inequalities or undermine the values that critical, life-improving actions - such as providing social care - are built on. This is a concern that drives Dr Caroline Green, Director of Research and Head of Public Engagement at the University of Oxford’s Institute for Ethics in AI, and lead of the Accelerator Fellowship Programme. Dr Green is rapidly becoming one of UK’s leading voices on the responsible use of artificial

--- DOC: Kingâ€™s College London | Michael Cook | King's College London
Dr Michael Cook Senior Lecturer in Computer Science Research interests - Computer science Contact details Biography Dr Mike Cook is a Senior Lecturer in Computer Science at King’s College London. His research focuses on artificial intelligence, creativity and applications of AI to game design and development. He is the designer of several game-designing AI systems including ANGELINA, Puck, Bluecap and Pixie, and is the author of Next Level, an upcoming book about creative technology and games. Research interests - Computational Creativity - Automated Game Design - Design & Analysis of Generative Software - General Game Playing - Computational Subjectivity Further information Archaeological Gameworld Affordances: A Grounded Theory of How Players Interpret Environmental Storytelling Smith Nicholls, F. & Cook, M., 16


